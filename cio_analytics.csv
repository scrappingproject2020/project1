category,blurp,imgrul,text,title,url,date
Analytics,Predictive analytics tools comb through your data to divine visions of your business future. Here’s an overview of the wide array of options available today.,https://images.idgesg.net/images/article/2019/09/prediction_predict-the-future_crystal-ball_hand-holding-crystal-ball_by-arthur-ogleznev-via-unsplash-100811997-large.jpg,"Somewhere along the way computers transformed from filing cabinets for data into crystal balls that foretell the future by examining that data to predict what might happen in a few seconds, a few days, maybe even a few years.Many of the tools for accomplishing this feat fall under the term “predictive analytics.” The term is a catch-all for algorithms developed over the years, from wildly different corners of statistics, artificial intelligence, machine learning and multidimensional mathematics. These tools emerged from the lab to populate corporate server farms and now they’re ready to guide business teams toward making the right decisions about allocating resources and reaping profits.The tools have two main roles, the more obvious of which is to peer into the sea of bits in the database and pluck out some vision for the future. They do this by supporting several good algorithms with various strategic approaches; some support dozens.The second role is less noticeable but often more time consuming. Preparing the data can be maddening because data is rarely as consistent or as clean as we need. If there are two files that need to be integrated, dates are often in differing formats using different time zones. Unifying challenges like these are easy. The more difficult ones involve missing fields or outliers that may be the result of an error — or could be an accurate omen that must be included in the data set. Removing mistakes while preserving the integrity of the data is a real challenge. All of the best tools offer good support for preparing the data and presenting the results.Many predictive analytics tools are brand extensions built by database developers and business analytics and reporting vendors, which have slowly merged traditional report generation with AI algorithms to produce tools that both summarize and offer predictions.",Top 15 tools for predictive analytics,https://www.cio.com/article/3566556/top-15-tools-for-predictive-analytics.html,2020-09-11
Analytics,Effectively managing supply chains has perhaps never been more important for organizations. The coronavirus pandemic has created significant market di,https://images.idgesg.net/images/article/2018/02/supply_chain_management_logistics_erp_enterprise_resource_planning_thinkstock_578796276-100749836-large.jpg,"Effectively managing supply chains has perhaps never been more important for organizations. The coronavirus pandemic has created significant market distruptions, shifting the way consumers and businesses purchase products and creating challenges for manufacturers to receive the materials they need to meet demand.Some organizations are finding that data analytics and related technologies such as artificial intelligence (AI) and machine learning hold the key to supply chain management excellence. Whether it’s a matter of ensuring supply chain integrity or navigating rapid growth and complexity, here is how several organizations are putting analytics to work to beneficial results.In 2013, NASA was directed by the U.S. Congress to improve its supply chain risk management processes, specifically as it relates to technology purchases of more than $800 million across IT and operational technology.Analytics has played a big role in helping the space agency comply with this initiative. Key has been the aeronautics and space research agency’s adoption of an AI-powered supply chain risk management tool from Interos to provide analytics and insight, says Kanitra Tyler, head of NASA’s Supply Chain Risk Management (SCRM) Service. “Our success with this tool ultimately led to our program becoming a shared service across NASA,” she says.",Analytics: Your supply chain’s competitive edge,https://www.cio.com/article/3573574/analytics-your-supply-chains-competitive-edge.html,2020-09-11
Analytics,"From powering customer-facing chatbots, to keeping track of contractual commitments, to making the most of meetings, natural language processing holds great potential to transform your business.",https://images.idgesg.net/images/article/2019/11/ai_artificial_intelligence_ml_machine_learning_abstract_face_by_kentoh_gettyimages_1042827860-100817767-large.jpg,"Recent improvements in As NLP becomes more accurate and more widely available, it has the potential to move from powering customer support chatbots on preset topics to handling qualitative, semi-structured and unstructured data. Finally delivering on “NLP breaks down words into their simplest form and identifies patterns, rules and relationships between them,” explains Walt Kristick, senior vice president of applied and advanced technology at apexanalytix. “It uses computer algorithms to parse and interpret written and spoken natural language to allow systems to learn and understand human languages.”NLP uses range from translation and language generation (for summaries, annotation, or even explaining other machine learning models), to classification and clustering, sentiment analysis and other information extraction. The simplest forms of NLP are already widely used, Kristick points out: spell-checking, suggested email and messaging responses, and virtual assistants such as Siri all use NLP, as do chatbots.“There is a growing demand for the ability to analyze and extract meaning for text and non-related data sources, especially in the healthcare and life sciences markets,” Kristick notes.",NLP poised to revolutionize the enterprise,https://www.cio.com/article/3566378/nlp-poised-to-revolutionize-the-enterprise.html,2020-09-11
Analytics,Many organizations are struggling to get business value from their analytics. Setting up analytics projects or an analytics organization is one thing ,https://images.idgesg.net/images/article/2020/02/data_analytics_risk_assessment_tracking_trends_graphs_by_ipopba_gettyimages-1150397416_2400x1600-100828857-large.jpg,"Many organizations are struggling to get business value from their analytics. Setting up analytics projects or an analytics organization is one thing but deriving value from analytics is another. And with the COVID-19 pandemic disrupting economies around the globe, companies will likely ""It's not about analytics. It's not even about insights. It's about impact. If you're not making an impact, you're wasting your time,"" says Mike Onders, chief data officer, divisional CIO, and head of enterprise architecture at Cleveland, Ohio-based KeyBank.Here, ruthless focus on business outcomes is key, as is the ability to rapidly prove analytics can have a business impact and then delivering results at scale.""We actually work backwards from specific business outcomes we're looking to achieve,"" says Shri Santhanam, executive vice president and general manager of global analytics and AI at Experian. ""Ultimately, ML [machine learning] and AI tend to be vehicles to get us to the ultimate goal, but really, what we talk about, what we share, what we drive with our customers is a better set of outcomes.""",Transforming analytics into business impact,https://www.cio.com/article/3572642/transforming-analytics-into-business-impact.html,2020-09-11
Analytics,"Strong data analytics is a digital business imperative — and it all begins with data governance, the right strategy and an emphasis on data-conscious culture. ",https://images.idgesg.net/images/article/2018/02/big_data_analytics_analysis_thinkstock_673266772-100749739-large.jpg,"Data and analytics remain top priorities for organizations in the digital era, with 37 percent of IT leaders saying that data analytics will drive the biggest chunk of their IT investments this year, ahead of security and risk management, according to CIO.com’s 2020 State of the CIO survey.And with that level of spending going toward analytics, the pressure is on to deliver results. Yet experts in this space say CIOs and their executive colleagues are falling short. “There are challenges in getting these initiatives across the goal line,” says Brad Fisher, a partner and the U.S. leader for data and analytics at KPMG.Following are four key areas that are hindering analytics success:",Why data analytics initiatives still fail,https://www.cio.com/article/3269012/why-data-analytics-initiatives-still-fail.html,2020-09-11
Analytics,Analytics has made itself indispensable for everything from business planning to infrastructure optimization. A set of five articles brings the broad benefits of data-derived insights to life. ,https://images.idgesg.net/images/article/2020/07/intro_ts_analytics__by-hakinmhan-getty-images_2400x1600-100851350-large.jpg,"The world bought into the idea of For decades, those armed with the At the same time, the ubiquity of analytics has given rise to the hottest specialized job on the planet: the data scientist. The multidisciplinary nature of this position leaves enterprises hunting for unicorns who know statistics, programming, probability, and very likely machine learning, not to mention whatever vertical expertise a company demands. The oracle-like status of the data scientist offers definitive proof of analytics' ascendency.Meanwhile, though the big data trend has cooled somewhat, big data analytics has permanently lodged itself in infrastructure, enabling engineers to process gargantuan log files to surface anomalies, inefficiencies, and vulnerabilities. And just about every company heavily invested in customer-facing applications now dumps terabytes of user clickstreams into the analytics hopper, enabling mass customization and UI tweaks that boost usability and revenue.To guide you on your own analytics journey, CIO, Computerworld, CSO, InfoWorld, and Network World have contributed five articles that examine today’s role of analytics in the enterprise through completely different lenses, from case studies to implementation recommendations.InfoWorld contributing editor Isaac Sacolick, a former CIO and CTO, kicks things off with a terrific primer entitled ""While Sacolick primarily focuses on the back end of analytics, Computerworld contributing writer Bob Violino trains his lens on the presentation layer in ""Leave it to CIO to highlight analytics' benefits on the ground. In ""Network World senior editor Michael Cooney homes in on a different type of special case in ""It's unlikely you'd write custom analytics code to monitor your SD-WAN deployment, but in many cases – particularly those that might involve a data scientist – the proprietary algorithms developed may be valuable trade secrets. That's what CSO contributing writer Stacey Collet addresses in ""In the age of analytics everywhere, that should be welcome news. Especially when augmented by machine learning, the insights derived from analytics will play an increasingly strategic role in steering your enterprise.",Insight everywhere: The state of analytics in 2020,https://www.cio.com/article/3566317/insight-everywhere-the-state-of-analytics-in-2020.html,2020-09-11
Analytics,IT leaders are already starting to reap the rewards promised by AI and machine learning -- and a recent survey reveals half are considering greater investment as we hit economic headwinds.,https://images.idgesg.net/images/article/2020/08/intro_ts_ai_ml_by-monsitj-getty-images_2400x1600-100853894-large.jpg,"By now most of us understand that, in our current era, artificial intelligence (AI) and its subset machine learning (ML) have little to do with human intelligence. AI/ML is all about recognizing patterns in data and automating discrete tasks, from algorithms that flag fraudulent financial transactions to chatbots that answer customer questions. And guess what? IT leaders appreciate the enormous potential.According to a A July Now’s the time to get your AI/ML strategy in shape. To that end, CIO, Computerworld, CSO, InfoWorld, and Network World have produced five articles that dissect the issues and provide meaningful recommendations.Although AI/ML will doubtless replace some jobs, Matthew Finnegan's Computerworld article, ""But effective AI/ML solutions come in many forms, as CIO's Clint Boulton recounts with a fresh batch of case studies, ""Contributor Neil Weinberg highlights a highly practical use of AI/ML with direct benefit to IT in ""ML in all its forms typically begins with finding patterns in large quantities of data. But in many instances, that data may be sensitive, as CSO contributor Maria Korlov reports in ""So where should you build your AI/ML solution? The public cloud providers offer highly attractive options, but you need to select carefully, argues Martin Heller, contributing editor for InfoWorld. In ""We're still generations away from any AI equivalent of human intelligence. In the meantime, AI/ML will progressively infiltrate almost every type of application, reducing drudgery and offering unprecedented capabilities. No wonder IT leaders believe it will have the greatest impact.",AI and machine learning: Powering the next-gen enterprise,https://www.cio.com/article/3570613/ai-and-machine-learning-powering-the-next-gen-enterprise.html,2020-09-11
Analytics,Self-service business intelligence has become the go-to tool for business decisions. Here’s how Qlik Sense and Tableau stack up on features and pricing.,https://images.idgesg.net/images/article/2018/02/big_data_analytics_analysis_thinkstock_673266772-100749739-large.jpg,"Business intelligence (BI) and analytics platforms are a staple of informatics for medium to large businesses. Visual-based data discovery has been a key component of BI since about 2004; this trend has moved the responsibility for analytics from IT to self-service by business analysts and managers, with support from data scientists and database administrators. The emphasis of BI has changed from generating monthly reports from the system of record, to interactively discovering and sharing trends, forecasts, and answers to business questions based on data from a variety of internal and external sources. Instead of needing months to make a decision, businesses that have adopted self-service visual data discovery can often decide on a course of action in a few days.How does one choose a self-service BI platform? Mostly, you want to find the platform that is the best fit for your company, both from the point of view of the users and from the point of view of the IT infrastructure.Does the BI platform match the skills of the people who will use it? Can your people learn and use it easily? Does it make analysts' jobs easier, or does it create more barriers than it destroys?Is it able to read all of your internal and external data sources? Can you easily clean and transform your data within the platform? Is the platform able to display all the charts you require? Can you share your analyses with anyone in the company, or only with licensed users?With these considerations in mind, let's examine (in alphabetical order) five market-leading BI platforms.",Qlik Sense vs. Tableau: Self-service analytics tools compared,https://www.cio.com/article/3569110/qlik-sense-vs-tableau-self-service-analytics-tools-compared.html,2020-09-11
Analytics,"Given its promise in driving business value, it’s no surprise that data analytics remains a top IT investment — but success is no guarantee.",https://images.idgesg.net/images/article/2019/11/man_with_umbrella_stands_waist-deep_in_water_as_rain_continues_to_fall_sadness_depression_failure_problems_disaster_recovery_by_gruizza_gettyimages-841211954_abstract_connections_by_stationary_traveller_gettyimages-804339826-100817799-large.jpg,"Data analytics can be enormously valuable for companies, providing deep insights into data that might not otherwise be surfaced.Because of this, data analytics continues to eat up a significant portion of IT budgets. Thirty-seven percent of IT leaders said analytics will drive the most IT investment at their companies this year, the highest single category, according to the But there are no guarantees that analytics investments will pay off. In fact, the discipline can be fraught with problems that can temporarily derail these projects or doom them to failure.Avoiding negative outcomes is within the grasp of any company that wants to exploit analytics — it just requires putting in the necessary preparation and work. Here are some steps that organizations can take to avoid data analytics disasters and disappointments.",6 tips for avoiding data analytics disaster,https://www.cio.com/article/3541012/6-tips-for-avoiding-data-analytics-disaster.html,2020-09-11
Analytics,Retailers looking to develop new customer experiences need to make artificial intelligence part of their digital transformation plans or risk falling further behind. ,https://images.idgesg.net/images/article/2018/02/fintech_shopping_retail_financial_transactions_thinkstock_828433478-100749753-large.jpg,"Before the coronavirus hit, consumer expectations were already changing and creating challenges in the retail industry. And CIOs, who historically had little to do with developing new customer experiences, were increasingly being tasked with driving innovation. To deliver Amazon-like here-and-now products and services and build brand loyalty, they are turning to artificial intelligence (AI) to improve the shopping experience for consumers both in stores and online. Of course, AI alone won’t transform retail but there are several key technologies that when married with AI can bring innovation to that industry. One is video analytics, which turns regular stores into intelligent stores that have visibility into consumer behavior for optimized merchandising. Retailers can leverage video for store analytics to enable things like heat maps that show where consumers are spending the most time in the store. That’s the kind of knowledge many retailers currently don’t have today.Intelligent stores require an assortment of applications for various use cases. Using video analytic software, retailers can build a distributed infrastructure for deploying multiple apps on the same server at each store. Video analytics can also be deployed for asset protection at self-checkout kiosks and to monitor employee theft. For an average retailer, shrinkage, or the loss of inventory, accounts for approximately 1.5 to 2 percent of revenue — a cost that can be reduced and added back into the bottom line with the help of AI.So, what does this look like in an actual store? Take a large retailer that has implemented an AI-powered asset protection solution at self-checkout kiosks, which can identify miss-scans and ticket switching. When someone tries to scan a bottle of wine with a bag of chips underneath, the app can recognize the product shape, lock the scanner, and notify store associates.",How AI is transforming retail,https://www.cio.com/article/3536829/how-ai-is-transforming-retail.html,2020-09-11
Analytics,The internet of things may be your key to data-driven transformation. Here’s how to turn vast troves of real-time IoT data into big-time business value.,https://images.idgesg.net/images/article/2020/05/tech_spotlight_iot_cio_thinkstock_2400x1600-100841119-large.jpg,"The internet of things (IoT) is increasingly becoming a key component of many companies’ data-driven transformation strategies. Indeed, organizations that have embraced IoT are already seeing benefits such as improved operational processes, better inventory management, and enhanced equipment maintenance — to name a few.But a successful IoT strategy is more than just connecting a bunch of devices and sensors to the internet and gathering data from these “things.” IT must establish the ability to effectively analyze the vast amounts of data IoT creates in order to make sense of it and gain real business insights.That’s why an analytics strategy for IoT should be a top priority for any company looking to get the most out of all the connectivity.Organizations can enjoy a number of advantages in leveraging the IoT data they gather, says Carlton Sapp, senior director and research and advisory leader at Gartner.These include contextual awareness of equipment and systems; improved decision-making, optimization and supervisory control of equipment and resources; reduced costs associated with data management; proactive, predictive and prescriptive management of equipment; and environmental compliance.These opportunities are pervasive in use cases such as fleet optimization and management, asset management, financial risk management, and smart cities, Sapp says.But they require a sound, streamlined approach to the data end of IoT. Here are several tips for dealing with IoT data, and getting the most out of these resources.Once an organization has an idea of its IoT analytics business goals, it needs to identify the key stakeholders who will be involved, says Stacy Crook, research director for IoT at IDC, and ascertain whether or those stakeholders require additional skills to make the project successful.“It is a well-known fact that data science skills are in short supply in the industry, but these are essential for IoT analytics projects,” Crook says. “So the project may require hiring new employees, or outsourcing certain parts of the project to third parties,” if in-house data science skills are thin.Organizations should also consider appointing a chief data officer (CDO) to champion IoT data analytics efforts and lead the data governance strategy, Crook says.Because IoT is essentially a big data problem, IDC suggests organizations consider how their existing infrastructure could also serve IoT use cases. “Although older big data architectures might have been focused on batch-oriented workloads, increasingly there are tools available to run real-time workloads over this same backbone,” Crook says.Leveraging the same infrastructure for various IoT workloads can have benefits in terms of preventing data siloes and providing the ability to more easily run cross-functional data analysis across those workloads, Crook says. “It can also provide data governance and security benefits,” she says.Companies need to start with the right IoT data architecture and understand how to manage IoT data at various locations.“Data emanating from IoT endpoints offers new and unique challenges, such as unreliable network access and combining devices that may be distributed over large distances and generate data in multiple formats over multiple protocols,” Sapp says.Today, most IoT data is telemetry data, but endpoints are increasingly emitting image and audio data that should be handled by persistent data stores, Sapp says. “Start with an appropriate IoT data architecture that will support the expected growth in the volume of IoT,” he says.Organizations often fail to effectively manage IoT data, due to a lack of a flexible/elastic data architecture. “Data will continue to grow, so design an architecture that leverages analytics and data mining techniques that identify critical information that can be used to improve processes, improve decision-making, or reduce costs,” Sapp says.For example, telecommunications companies are successful at reducing the cost of moving data over a network by taking advantage of IoT analytics at the network edge that reduces ""noisy data."" “Those organizations focus on scalable edge-centric data architectures that are designed for rapid knowledge discovery in IoT data,” Sapp says.The IoT data architecture should also support analytics across data pipelines (via streaming) and in local data stores to take advantage of faster decision-making and reduced costs, Sapp says.Organizations can do this by focusing on data-centric design patterns when creating and deploying IoT analytics, including the use of event-driven architectures.“Start by distributing analytics at the edge, on streaming pipelines, on the platform, and in the enterprise,” Sapp says. Organizations should take advantage of streaming IoT data pipelines as a source to deploy analytics to improve latency and reduce costs and security vulnerabilities, he says.For example, the U.S. Department of Defense often performs analytics over streaming data pipelines to reduce the throughput of data over a network, Sapp says. It also leverages IoT edge analytics to avoid sending any data over a network, using operational analytics closer to the source of data.There will most likely be multiple analytical environments deployed to support disparate analytics, Sapp says. “Environments may range from operating systems to embedded analytics software,” he says. “Be prepared to deploy IoT analytics across a landscape that spreads from the network edge to the corporate enterprise. For example, utility organizations leverage distributing IoT analytics across various infrastructures to support fleet management.”Organizations should enhance what they can do with IoT data by taking advantage of AI, Sapp says.“Edge intelligence is an emerging field that uses AI as an analytic method deployed at the network edge, to develop intelligent applications from IoT data,” Sapp says.These intelligent applications range from video surveillance to intelligent supervisory control and data acquisition (SCADA) systems. For example, environmental organizations use IoT data to build intelligence control systems to maintain environmental compliance.Adding AI to the IoT architecture Is becoming an operational imperative, Sapp says. IoT systems, including endpoint devices, must become smarter and more autonomous in order to deal with the ever-increasing magnitude of data. To make these systems smarter, organizations need to deploy AI and machine learning.Given the huge volumes of data generated by IoT applications, for many organizations the cloud will be the only answer for getting a hold on data management, including analytics.“It’s not worth it to build the scale and speed needed to really manage this volume in real time,” says Greg Meyers, group CIO and chief digital officer at Syngenta, a company that produces agrochemicals and seeds.“Trying to manage it yourself in your own data center or on your own infrastructure is hugely self-defeating,” Meyers says.IoT gives Syngenta the ability to manage its customers’ farms and fields, which are usually arbitrarily aggregated into small micro segments. “Humans are great at managing averages, but computers are better at managing variability,” Meyers says. “IoT lets us understand why things that are happening in one area are different than things that are happening maybe 100 meters away.”Leading public cloud vendors are offering services to help companies with IoT analytics. For example, Amazon Web Services (AWS) offers IoT Analytics, a managed service that enables companies to run and operationalize sophisticated analytics on massive volumes of IoT data, without having to worry about the cost and complexity typically required to build an IoT analytics platform.Microsoft offers Azure IoT, which includes a data analytics service called Azure IoT Central to provide analytics capabilities to examine historical trends and correlate various telemetries from connected devices. And Google provides Cloud IoT, a set of tools to connect, process, store, and analyze data both at the network edge and in the cloud.Organizations need to ensure they have governance, security, and privacy mechanisms in place for IoT data analytics processes. Much of the data generated by IoT will be sensitive or have competitive value — and needs to be carefully managed and protected.“Reassess current data governance practices [to] include machine data,” says Nicholas Colisto, vice president and CIO at Avery Dennison, a manufacturer and distributor of adhesive materials, apparel branding labels, and tags.“From my experience, IoT governance is an immature area,” Colisto says. “In a previous company, I faced a situation where a business unit deployed an IoT system without seeking IT involvement, and simple operational tasks and tools to audit devices and apply firmware were not considered.”Data generated from IoT can be valuable both inside and outside the company.Chemical manufacturing company Texmark Chemicals launched an effort to modernize operations at its plant by deploying sensor-enabled pumps. Using technology from Hewlett Packard Enterprise and Aruba Networks, the company gathers operational data from pump sensors that measure temperature, pressure, vibrations, flow, and power. This data is analyzed to predict equipment failures before they happen.Through a “workshopping” process, Texmark realized that having sensor-enabled equipment not only helps the company monitor its assets and processes, but has opened the possibility to new business models, says Doug Smith, CEO.The use of IoT becomes an additional selling factor prior to contract negotiations, Smith says. “Clients are beginning to realize the value of having access to data coming off contractor assets,” such as industrial pumps, he says. Clients then ask Texmark to add sensors to their pumps and provide them with the data.“In essence, we are developing a library of historic performance attributes that can be catalogued and shared with other companies using similar equipment,” Smith says. “When deploying machine learning analytical models, the more data acquired, the greater the accuracy in the analytical prediction.”By sharing IoT data with pump manufacturers or fellow suppliers, “we could prove the new business model, as long as the documentation is clear and precise,” Smith says. “Meanwhile, customers are impressed we have deployed instrumentation and software analytics to capture, analyze, and report on such data — allowing for more cost-effective decisions.”This new data-as-a-service offering enabled by IoT can distinguish Texmark from competitors, Smith says, and creates a stronger bond with customers while empowering employees to achieve more from their work.",IoT analytics: Reaping value from IoT data,https://www.cio.com/article/3542670/iot-analytics-reaping-value-from-iot-data.html,2020-09-11
Analytics,The challenge of dealing with COVID-19 comes on top of recent trends in data-driven innovation and presents challenges and opportunities for companies across all sectors.,https://images.idgesg.net/images/article/2020/04/declining_line_graph_decreasing_trend_chart_virus_morphology_covid-19_coronavirus_pandemic_economic_impacts_by_rawpixel_adj_id_2306343_cc0_2400x1600-100839289-large.jpg,"In a matter of weeks, organizations implemented remote working for many employees, driving internal changes that would have taken years to plan and roll out only a few months ago. This has shifted the focus of operations to the vital role that technology now plays in our businesses.The genie cannot be put back in the bottle. This forced global experiment will change how businesses operate over the next decade and beyond. Several key technologies will play a vital part in these developments, with the collection and exploitation of data being the common link.The rise of robots in automated factories and warehouses was well underway before workplaces shuttered their operations in response to COVID-19. However, the need for social distancing and safe workspaces has driven a significant increase in the demand for robotic devices and helpers. In the U.S., companies including Brain Corp, Xenex and Simbe Robotics are taking on extra staff to build and maintain the robots retailers and hospitals now need to sanitize buildings and stock shelves.While these devices help keep workers safe, they are also generating data that is used to streamline workflows and business planning. For example, Simbe’s Tally robots collect real-time data on where products are located on shelves, helping customers and stock pickers find what they are looking for in less time. Such robotic solutions will continue to harvest new data, reducing operating costs and improving customer service as they go. Businesses that implement them will find themselves at an advantage once the current crisis ends through their lowered cost base and organizational learning.",Is your business about to be disrupted by data?,https://www.cio.com/article/3541568/is-your-business-about-to-be-disrupted-by-data.html,2020-09-11
Analytics,"Rita Fisher, CIO and SVP of Supply Chain, discusses her approach to digitizing plant operations at the global consumer products company.",https://images.idgesg.net/images/article/2020/04/rita_fisher_headshot_1200x800-100839423-large.jpg,"When customers demand faster delivery and lower costs, consumer packaged goods companies need to optimize their manufacturing and supply chain operations. That’s where intelligent factories come in. But how do you drive change in factories that have been run in the same way for decades? According to Rita Fisher, CIO and SVP of Supply Chain at Reynolds Consumer Products, it is about showing a plant early value, and then being with them every step of the way.Martha Heller: How are digital technologies impacting Reynolds Consumer Products?Rita Fisher:Reynolds Consumer Products (RCP) also has a private label business, and for those customers, it is all about price and quality.The question we our asking ourselves is: what kind of supply chain and manufacturing capabilities do we need to deliver on these new customer expectations in speed-to-market and lowest cost-to-serve?How are you creating the cultural change necessary for digital transformation?Our vision is to digitize our company with full support from the RCP leadership team. We started with the knowledge that customer and consumer expectations are changing, and that the only way we can meet those expectations is by rethinking and reimagining how we run our business.What is the vision for digitizing the company?Our vision for the digital enterprise is built on five major pillars: Digitizing the customer experience.The digital supply chain. The intelligent factory. The digital workforce. Digital products and services.Let’s focus in on the intelligent factory. What does that program entail?The intelligent factory program has three major components.The first is operational transformation, which instills robust, Lean principles into our manufacturing processes, and delivers better data to drive decisions. It’s not only about the data, it’s about showing people how to turn the data into insights and the insights into action to achieve business benefits.The second component is the digital manufacturing group, which we built to work directly with the plants, to help them with technology expertise, implementation, and change management.And the third is actually building the intelligent factories, which use IoT and data science to provide predictive insights that improve overall throughput and reduce our costs. Here, we’ve deployed new data collection tools and software to enable production tracking and monitoring.  We are also using What kind of results is the intelligent factory demonstrating?Now that the program is in place, we are seeing real results. For example, in reviewing six months of plant data, we were able to determine the most optimal settings for every line, to decrease downtime and scrap to achieve maximum capacity. That information has allowed us significantly to increase our output without additional investments.But it is in the area of That was a huge eye-opener for the manufacturing teams, where they truly saw the value in the program. Through predictive maintenance, we are unlocking a lot of capacity.What have been some challenges in rolling out the intelligent factory?The first challenge was purely technical. We had made assumptions about what capabilities the plants had and how everything worked. But we had to adjust our plan once we looked further into implementation.The second challenge was getting people in the plant to buy into the intelligent factory program. Jobs were changing, and we wanted to be sure all team members joined us in this effort.We learned that we had to help people in the plants see what is possible before we could get them fully on board. We are bringing in new tools, but also new training to show people how to get the most value.How did you bring the people along?It is so critical to the success of the program to make sure your early pilots are successful, because our new investments change what have historically been viewed as manufacturing best practices.We didn’t build the entire platform right away, because that would be complex, so we prioritized in an effort to make thoughtful and deliberate steps in the process.Day by day, we were there with the team members in the plants every step of the way. We learned that you cannot run a program like this without having resources on-site. You have to be there physically. You have to become part of their team and a trusted partner.",Predictive analytics unlocks factory capacity at Reynolds,https://www.cio.com/article/3539273/predictive-analytics-unlocks-factory-capacity-at-reynolds.html,2020-09-11
Analytics,Tableau's COVID-19 Data Hub is an example of how data and analytics companies are mobilizing data resources to help combat the novel coronavirus.,https://images.idgesg.net/images/article/2020/03/coronavirus_lab-research_analytics_by-da-kuk-getty-100835287-large.jpg,"The COVID-19 pandemic has impacted nearly every aspect of life around the globe, and data analytics vendors are mobilizing to help individuals, scientists, governments, and businesses understand the shape and scope of the crisis. As its response, Tableau Software has created the The Data Hub is a resource for accessing and analyzing the latest data on the novel coronavirus from vetted data sources, including Johns Hopkins University, the Centers for Disease Control and Prevention (CDC), and the World Health Organization (WHO). The hub offers dashboards created by Tableau and other organizations, as well as resources for creating your own visualizations from the data.The effort is aimed at helping organizations better understand the potential effects of the virus on their operations, from mapping the outbreak against employee location data to help determine work from home (WFH) policies, to tracking inventories of clinical supplies.""It evolved organically out of some of the things we were doing for ourselves,"" says Steve Schwartz, head of public affairs at Tableau. ""We were following the continued spread of the disease, first in Wuhan in China and then as it started to become clearer that it was moving globally. Then eventually it popped up right in our own backyard in Seattle.""Tableau initially sought to contextualize its own situation through case reporting data, Schwartz says: ""It started organically there, and some of the challenges we had working with the data set from Johns Hopkins quickly turned into us working with some of our community leaders, Zen Masters, to create first a stream of normalized, reshaped data, and then a jumpstart dashboard for ourselves to do our analysis, and then starting to make that stuff available to the public.""When the COVID-19 Data Hub first launched, the Johns Hopkins data required a lot of manual data transformation. Schwartz says customers were telling Tableau they were spending hours a day reworking the data to perform their own analysis. For instance, data sources might refer to the Vatican by that name or as the Holy See. When the data sources start getting into sub-regional jurisdictions around the world, things got even more complicated, with many places having different names depending on the source.So, the Data Hub evolved as a ready-to-use data stream of cleaned and formatted data, pre-loaded into a starter dashboard to make it easier for people to connect and blend their own organization's data with the Johns Hopkins data.""We're thinking about everything from huge global multinationals to small businesses that are trying to make sense of what this means,"" Schwartz says. ""You've got employees, you have your customers, their supply chains. Every business function, every organizational function is going to have a dimension of it that is going to be touched by this situation.""In addition to WFH policies, Schwartz says organizations are using the data to explore their supply chains and how the pandemic affects them. Medical supplies are an easy example.""You don't have to look too much further past the healthcare industry itself to discover the cotton swabs are being made in Italy and the diagnostics are being made in Switzerland and we're trying to move all of this really core, essential material all over the world in these just-in-time supply chains.""The data is helping organizations understand which parts of those supply chains are hardest hit by the disease and may not be able to deliver in a just-in-time scenario.Government programs and financial services organizations are also making use of the data as they seek to understand the impact of shelter-in-place policies and to understand where individual support programs, small business loan programs, and the like are most needed.""I just heard from a couple of the laboratory pharmaceutical companies that they were using a lot of this data to help inform where to distribute testing kits,"" Schwartz says. ""They're using this core data to figure out where to distribute nationally and globally.""There are currently thousands of visualizations published through the Data Hub, ranging from public health and case tracking (globally and broken down by nation and region), visualizations of emergency food resources, keywords used in news media coverage, U.S. retail closures, economic recovery signals, and more.Tableau is not the only data and analytics company providing resources to individuals and organizations grappling with the pandemic. A few examples include:",Tableau joins effort to fight pandemic with data,https://www.cio.com/article/3538814/tableau-joins-effort-to-fight-pandemic-with-data.html,2020-09-11
Analytics,To make the most of machine learning you have to train your models right. Here’s how to get reliable results from your data.,https://images.idgesg.net/images/article/2019/11/ai_artificial_intelligence_ml_machine_learning_vector_by_kohb_gettyimages_1146634284-100817775-large.jpg,"To make decisions more quickly and accurately, enterprises are increasingly turning to machine learning, arguably today’s most practical application of AI. Machine learning systems apply algorithms to data to glean insights into that data without explicit programming: It’s about using data to answer questions. As such, companies are applying machine learning to a wide array of issues, from customer purchasing patterns to predictive maintenance.But before a machine learning system can answer questions, it must first be trained on data and outcomes. That’s because, while not explicitly programmed, machine learning systems need to develop and hone their ability to make predictions from data through experience with the same kind of data it will use to answer questions. For example, to predict whether a component is about to fail, a machine learning system must first be trained to do so by being fed sets of sensor readings from both functional and failing components.This apparently prosaic stage between choosing your machine learning algorithm and deploying your data model is actually a key step in getting machine learning right: Get it wrong and you’ll end up with a system that doesn’t deliver what you want. There are some common mistakes that often happen when training machine learning systems; there are also decisions that need to be made early on, long before a machine learning system is deployed, that will be challenging and costly to address later.Here’s what to look out for.",12 tips for machine learning training,https://www.cio.com/article/3541310/12-tips-for-machine-learning-training.html,2020-09-11
Analytics,True data value depends on business insights. Here’s how to ensure your analytics initiatives make sense to those who will benefit the most.,https://images.idgesg.net/images/article/2020/05/sour-taste_lemon-wedge_slice_binary_by-nicepear-jakarta-via-unsplash-100842154-large.jpg,"Data analytics is one of the most powerful resources enterprises have at their disposal. But the value of analytics can diminish significantly if the tools and process in use are not friendly and broadly available to the business users who need them.Afterall, these are the people who will be leveraging the data to gain insights in areas such as sales, marketing, product development, customer support, and customer experience.“Data by itself is not analytics,” says Bryan Phillips, senior vice president of technology and CIO at Alpha Packaging, a manufacturer of bottles and jars. “At some point in time you have to understand the problems, issues, opportunities that the data is indicating, otherwise it’s just data or pretty pictures.”Here are seven ways organizations fail to ensure that their data analytics efforts are friendly toward business users.",7 sure-fire ways to sour the business on analytics,https://www.cio.com/article/3543868/7-sure-fire-ways-to-sour-the-business-on-analytics.html,2020-09-11
Analytics,"New tools bundle data cleanup, drag-and-drop programming, and the cloud to help anyone comfortable with a spreadsheet to leverage the power of data science.",https://images.idgesg.net/images/article/2019/06/data-scientist_woman-at-virtual-monitor_user-interface_tools-for-data-science-by-metamorworks-getty-100798723-large.jpg,"The math of Just as Data scientists used to wring their hands preparing data for analysis by crafting custom routines in Python, Java or their favorite language so that sophisticated statistical tools in R or SASS could do their job. The marketplace now offers tools that bundle together several hundred well-engineered routines into a package that does much of the repetitive and unpleasant data cleanup and standardization for you.These new tools open the opportunity for The tools also unlock the cost-saving power of the cloud. Data scientists no longer need powerful computers to crunch big data sets. Instead we can rent even bigger, faster machines in the cloud by the second, increasing processing speed while saving money by returning the hardware to the pool when the reports are done.",9 tools that make data science easier,https://www.cio.com/article/3400907/6-tools-that-make-data-science-easier.html,2020-09-11
Analytics,"The addition to the Planning Analytics portfolio gives SMBs and business units in the enterprise an on-ramp to integrated, AI-powered planning and forecasting without relying on IT support. ",https://images.techhive.com/images/article/2016/11/20151027-ibm-sign-100625227-orig-100696117-large.jpg,"IBM added a new layer to its Planning Analytics portfolio Wednesday with the release of Planning Analytics On Demand. The new offering is intended for SMBs and enterprises seeking to migrate individual departments from manual budgeting and forecasting processes to an automated, AI-powered process.Many organizations, large and small, still rely on manual IBM’s""Where we see Planning Analytics On Demand coming in is an extension to thatAmong the AI-powered capabilities of the offering is the ability to ingest existing Excel spreadsheets used for planning and use them to build a collaborative model and generate dynamic dashboards.""The other area that we generally see with AI is the ability to identify variances in plans and things like that that may come from exogenous data,"" Marmer says.Marmer says these capabilities are essential to help organizations move from an annual planning process ""They were seeing a 30 percent drop in business,"" Marmer says. ""They still had a takeout business, delivery business, and curbside pickup, but without having the dining services, that's a challenge to them. They've been able to go back and model exactly this: If this is the expected time to open, this is what it means, and this is when I need to bring resources back so I can manage my capital allocation better.""Planning Analytics ""They can create models, workbooks, invite others to participate, much like they would do in a system that was managed by their systems team, but now they can do it self-service on their own,"" Marmer says.Planning Analytics ",IBM adds AI-fueled forecasting to Planning Analytics platform,https://www.cio.com/article/3544611/ibm-adds-ai-fueled-forecasting-to-planning-analytics-platform.html,2020-09-11
Analytics,Process mining is a methodology by which organizations collect data from existing systems to objectively visualize how business processes operate and ,https://images.idgesg.net/images/article/2019/08/nw_cso_growth_scale_expansion_double-exposure_businessman_tablet_charts_graphs_cityscape_by_tzido_gettyimages-611747524_2400x1600-100807804-large.jpg,"Process mining is a methodology by which organizations collect data from existing systems to objectively visualize how business processes operate and how they can be improved. Analytical insights derived from process mining can help optimize digital transformation initiatives across the organization.In the past, process mining was most widely used in manufacturing to reduce errors and physical labor. Today, as companies increasingly adopt emerging automation and AI technologies, process mining has become a priority for organizations across every industry. Process mining is an important tool for organizations that are committed to continuously improving IT and business processes.Process mining begins by evaluating established IT or business processes to find repetitive tasks that can by automated using technologies such as For example, an IT department might decide to automate its help desk ticketing system. Previously, an employee would take time to review a ticket, determine the correct category and assign it to the right employee. IT departments can create automated processes to categorize and assign tickets as they come in — freeing up workers to spend more time addressing customer issues. Once these automated processes are in place, however, it’s equally important to ensure the process regularly delivers the intended outcome. As new technologies are implemented, process mining can help the company retool the process to accommodate new ticket categories, staffing changes and varying industry trends.Process mining enables organizations to ensure automated processes are efficient, consistent and reliable. With process mining, companies can enable automated decision making, simulate processes to predict future outcomes, identify gaps in organizational leadership and ensure implemented processes are continuously improved. There are three classes of process mining techniques, each of which reflects a specific use case or focus for process mining: Plenty of third-party services are available to help companies tackle the job of process mining. These software tools help companies collect the relevant data they need and deliver insightful analytics based on the data they pull.Process mining software can help simplify process documentation and enable companies to make quick changes if new compliance regulations are introduced. It’s important to continuously monitor processes to ensure the best possible outcomes. While you can’t always control the outcome due to variations, it is possible to control, fix or improve the process to create better products, services and tools.Process mining tools can automatically create visual maps for organizations to see step-by-step how a process works, where it works best or breaks down so companies can make incremental improvements over time to create better outputs. There are plenty to choose from, some popular process mining tools and software include:",What is process mining? Refining business processes with data analytics,https://www.cio.com/article/3562428/what-is-process-mining-refining-business-processes-with-data-analytics.html,2020-09-11
Analytics,Artificial intelligence (AI) is something every IT organization must have in place to succeed. Or so you would think given the steady hype exhorting t,https://images.idgesg.net/images/article/2019/07/cio_ai_artificial-intelligence_3d-drawing_facial-recognition_face-abstract_anatomy-100801655-large.jpg,"Artificial intelligence (AI) is something every IT organization must have in place to succeed. Or so you would think given the steady hype exhorting the technology’s importance.Yes, AI can provide business value. No, it’s not going to magically solve all your organization’s issues.Still, approached rationally, AI can advance your enterprise systems and thus your business operations. To understand where enterprise IT can meaningfully take advantage of AI today, CIO.com interviewed AI analysts Kjell Carlsson of Forrester Research, Charley Rich of Gartner, and Mickey North Rizza of IDC.Vendors often claim that some AI secret sauce in their wares will revolutionize your business if only you deployed their offerings. Don’t believe it. “Be suspicious if it looks like anything you would have seen in a movie,” Carlsson says.",Where enterprise IT can really apply AI,https://www.cio.com/article/3562468/where-enterprise-it-can-really-apply-ai.html,2020-09-11
Analytics,Here's our rundown of what makes these 10 analytics vendors the biggest power players within the enterprise.,https://images.idgesg.net/images/article/2020/02/data_analytics_risk_assessment_tracking_trends_graphs_by_ipopba_gettyimages-1150397416_2400x1600-100828857-large.jpg,"Enterprises are investing heavily in data analytics, business intelligence (BI), and cognitive capabilities. According to IDG's State of the CIO 2020 report, 37 percent of IT leaders say that data/business analytics will drive the most IT investment at their organization this year.The landscape is in flux as web scale businesses continue to displace old-guard business analytics vendors and those vendors in turn seek to modernize and innovate to maintain their footing.Here's our list of the 10 most powerful companies in data analytics, offering everything from traditional BI to cutting-edge artificial intelligence and machine learning capabilities.Why they're here: ",10 most powerful data analytics companies,https://www.cio.com/article/3534511/10-most-powerful-data-analytics-companies.html,2020-09-11
Analytics,Decision support systems are a subset of business intelligence aimed at helping organizations make informed business decisions based on vast troves of analyzed data.,https://images.idgesg.net/images/article/2019/11/path_businessman_confused_decision_technology_data_binary_plotted_points_gettyimages_by_francescoch_601398828_by_ivanastar_901412996-100817844-large.jpg,"A decision support system (DSS) is an interactive information system that analyzes large volumes of data for informing business decisions. A DSS supports the management, operations, and planning levels of an organization in making better decisions by assessing the significance of uncertainties and the tradeoffs involved in making one decision over another.A DSS leverages a combination of raw data, documents, personal knowledge, and/or business models to help users make decisions. The data sources used by a DSS could include relational data sources, cubes, data warehouses, electronic health records (EHRs), revenue projections, sales projections, and more.The concept of decision support systems grew out of research conducted at the Carnegie Institute of Technology in the 1950s and 1960s, but really took root in the enterprise in the 1980s in the form of executive information systems (EIS), group decision support systems (GDSS), and organizational decision support systems (ODSS). These says, as organizations become increasingly focused on data-driven decision making, Decision support systems and Whereas BI is a broad category of applications, services, and technologies for gathering, storing, analyzing, and accessing data for decision-making, DSS applications tend to be more purpose-built for supporting specific decisions. For example, a business DSS might help a company project its revenue over a set period by analyzing past product sales data and current variables. Healthcare providers use clinical decision support systems to make the clinical workflow more efficient: computerized alerts and reminders to care providers, clinical guidelines, condition-specific order sets, and so on.In the book Data-driven DSS.Model-driven DSS. Knowledge-driven DSS. Document-driven DSS. Communication-driven and group DSS.Decision support systems are used in a broad array of industries. Example uses include:According to According to ",Decision support systems: Sifting data for better business decisions,https://www.cio.com/article/3545813/decision-support-systems-sifting-data-for-better-business-decisions.html,2020-09-11
Analytics,"BI and data visualization skills are in demand and Tableau certifications are a great way to get ahead. Here's our guide to Tableau’s Desktop and Server certs, including costs, training, and value.",https://images.idgesg.net/images/article/2019/10/certification_mortar-board_graduate_graduation_college_expert_by-wittayayut_870798666-100814348-large.jpg,"Data visualization platform Tableau is one of the most widely used tools in the rapidly growing business intelligence (BI) space and individuals with skills in Tableau are in high demand.Market intelligence and advisory firm With the market for data visualization rising and Tableau’s position well established, certification for Tableau skills can present a lucrative path to career growth. Here's a guide to Tableau's array of certifications.According to Pearson VUE's latest Tableau's certifications, in particular, focus on performance-based testing rather than theory in an effort to verify a candidate's ability to apply the subject matter in a real work environment. Tableau says more than 20,000 people have earned more than 25,000 overall Tableau Certification titles.Here are some of the most popular job titles related to Tableau certifications and the average salary for each position, according to data from Certificates for Tableau skills are available both for business professionals who analyze data using the platform’s Tableau Desktop front end and for IT pros charged with administering Tableau Server, either on premises or self-hosting in a public cloud. These two strains for certification break down as follows.This certification validates a foundational knowledge of Tableau Desktop and data analytics to solve problems. It demonstrates understanding of Tableau core concepts and terminology and the ability to connect to, prepare, explore, and analyze data, and to share insights. Candidates must have at least three months of experience applying their knowledge in Tableau Desktop. The certification does not expire.Exam: Fee: Suggested training: This certification is intended for individuals with a comprehensive understanding of functionality in Tableau Desktop and at least five months of experience. It validates the user is proficient in the features and functionality of Tableau Desktop to analyze data and solve problems. Individuals with this certification can apply data mapping, data preparation, and calculation skills in more advanced data analysis. The Tableau Desktop Certified Associate title is active for two years from the data it is achieved.Exam: Fee: Suggested training: This certification is intended for individuals with advanced knowledge and skills in Tableau Desktop and at least one year of dedicated and practical experience with it. It validates that the holder can quickly analyze unfamiliar data to determine the most effective way to visually communicate insights to the intended audience with a polished, cohesive story using visual best practices. Candidates must be an active Tableau Desktop Certified Associate or Tableau Desktop Certified Professional. The title is active for three years from the date it is achieved.Exam: Fee: Suggested training: This certification is intended for individuals with a comprehensive understanding of Tableau Server functionality in a single-machine environment who have approximately four to six months of experience. Typical roles include system administrators and consultants. Individuals with this title can plan a deployment; install and configure Tableau Server; administer users, groups, projects, and content; and backup, restore, upgrade, and troubleshoot Tableau Server problems. The title is active for two years from the date it is achieved.Exam: Fee: Suggested training: This certification is intended for individuals with a comprehensive understanding of Tableau Server functionality in a single-machine and enterprise configuration. Candidates should have at least nine months of hands-on Tableau Server experience. Typical roles include system administrators, system architects, IT representatives, implementers, or consultants. Individuals with this certification can plan and implement a high-availability (HA) installation, and configure, monitor, maintain, and troubleshoot all aspects of a product environment. Candidates must be an active Tableau Server Certified Associate. The title is active for three years from the date it is achieved.Exam: Fee: Suggested training: ",Tableau certification guide: Kick-start your analytics career,https://www.cio.com/article/3546313/tableau-certification-guide-kick-start-your-analytics-career.html,2020-09-11
Analytics,"AI experimentation is high, but deriving value from deployments is challenging, say experts from BCG and Gartner, who recommend IT-business collaborate as a solution.",https://images.idgesg.net/images/article/2019/11/ai_artificial_intelligence_man_graphic_interface_data_by_art24hr_gettyimages_1157378096-100817765-large.jpg,"The vast potential AI holds for businesses worldwide is of little doubt. But flawed strategy, poor approaches to process change, expertise shortfalls and a general lack of technical understanding prevent many enterprises from deriving value from artificial intelligence.Among the 90 percent of companies that have invested in AI fewer than two out of five say they’ve made any business gains, according to And while implementing AI Many businesses let IT shepherd AI development and deployment, treating it much the same way they might the deployment of ERP systems, says Shervin Khodabandeh, a BCG partner who co-leads the firm's GAMMA AI practice. This is a significant misstep because general AI solutions won’t help the business, Khodabandeh says.",5 hurdles to AI value — and how to overcome them,https://www.cio.com/article/3534470/5-hurdles-to-ai-value-and-how-to-overcome-them.html,2020-09-11
